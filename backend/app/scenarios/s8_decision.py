"""
S8 Decision Agent - CEOå†³ç­–å†›å¸ˆ
ä¸»æ‰“ï¼šä¼ä¸šå¤§è„‘ï¼Œå…¼é¡¾ä¸»åŠ¨å¼
"""
from typing import Dict, List, Any, Optional
import json
from datetime import datetime
from app.core.agent import ScenarioOrchestrator, AgentState, register_scenario
from app.core.memory import MemoryManager
from app.core.llm import LLMClient
from app.core.mcp import get_tool_registry
from app.core.event_bus import get_event_bus, EventNames


@register_scenario("S8")
class S8DecisionAgent(ScenarioOrchestrator):
    """S8 CEOå†³ç­–å†›å¸ˆAgent"""

    _instance = None  # å•ä¾‹å®ä¾‹
    _is_processing_update = False  # é˜²æ­¢é‡å¤å¤„ç†

    def __new__(cls, scenario_id: str, memory_manager: MemoryManager, llm_client: LLMClient):
        """å•ä¾‹æ¨¡å¼ï¼šç¡®ä¿åªæœ‰ä¸€ä¸ªAgentå®ä¾‹"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self, scenario_id: str, memory_manager: MemoryManager, llm_client: LLMClient):
        # åªåˆå§‹åŒ–ä¸€æ¬¡
        if self._initialized:
            return

        super().__init__(scenario_id, memory_manager, llm_client)
        self.event_bus = get_event_bus()
        self.current_report = None  # ä¿å­˜å½“å‰æŠ¥å‘Šï¼ˆç”¨äºä¿®æ­£ï¼‰
        self.report_version = "v1.0"

        # è®¢é˜…è®°å¿†æ›´æ–°äº‹ä»¶ï¼ˆåªè®¢é˜…ä¸€æ¬¡ï¼‰
        self.event_bus.subscribe(EventNames.MEMORY_UPDATED, self.on_memory_updated)
        print(f"âœ… S8 Agentå·²åˆå§‹åŒ–å¹¶è®¢é˜…äº‹ä»¶")

        self._initialized = True

    async def generate_report(self, input_data: Dict = None) -> Dict:
        """
        ç”ŸæˆCEOæ™¨æŠ¥

        Args:
            input_data: è¾“å…¥æ•°æ®ï¼ˆå¯é€‰ï¼‰

        Returns:
            å®Œæ•´æŠ¥å‘Š
        """
        print(f"ğŸ“Š å¼€å§‹ç”ŸæˆCEOå†³ç­–å†›å¸ˆæ™¨æŠ¥ ({self.report_version})...")

        # èŠ‚ç‚¹1: æ±‡æ€»åŠ©æ‰‹
        summary = await self._node_summary(input_data)

        # èŠ‚ç‚¹2: å¼‚å¸¸/é£é™©åŠ©æ‰‹
        risks = await self._node_risk_detection(summary)

        # èŠ‚ç‚¹3: ç­–ç•¥å»ºè®®åŠ©æ‰‹
        recommendations = await self._node_recommendations(summary, risks)

        # æ„å»ºå®Œæ•´æŠ¥å‘Š
        report = {
            "version": self.report_version,
            "generated_at": datetime.now().isoformat(),
            "summary": summary,
            "risks": risks,
            "recommendations": recommendations,
            "status": "pending_confirmation"  # ç­‰å¾…èŠ‚ç‚¹4ç¡®è®¤
        }

        # ä¿å­˜å½“å‰æŠ¥å‘Š
        self.current_report = report

        # è§¦å‘äº‹ä»¶
        await self.event_bus.emit(
            event_name=EventNames.REPORT_GENERATED,
            data={
                "version": self.report_version,
                "report": report
            },
            source="s8_decision_agent"
        )

        return report

    async def _node_summary(self, input_data: Dict = None) -> Dict:
        """èŠ‚ç‚¹1: æ±‡æ€»åŠ©æ‰‹"""
        print("  [èŠ‚ç‚¹1] æ±‡æ€»åŠ©æ‰‹...")

        # æ¨é€èŠ‚ç‚¹å¼€å§‹çŠ¶æ€
        await self.event_bus.emit(
            event_name="node_status",
            data={
                "node": "summary",
                "status": "working",
                "message": "æ­£åœ¨æ±‡æ€»ç»è¥æ•°æ®å’Œå…³é”®æŒ‡æ ‡..."
            },
            source="s8_decision_agent"
        )

        # 1. ä»MCPå·¥å…·è·å–ç»è¥æ•°æ®
        analytics_tool = get_tool_registry().get_tool("query_analytics")
        if analytics_tool:
            metrics_result = await analytics_tool.execute(metric="all")
            metrics_data = metrics_result.get("data", {})
        else:
            # å…œåº•ï¼šä»æ¨¡æ‹Ÿæ•°æ®åŠ è½½
            import os
            import json
            data_path = "data/analytics.json"
            if os.path.exists(data_path):
                with open(data_path, 'r', encoding='utf-8') as f:
                    metrics_data = json.load(f).get("metrics", {})
            else:
                metrics_data = {}

        # 2. ä»è®°å¿†ç®¡ç†å™¨å¬å›ä¼šè®®å…±è¯†
        memories = self.memory_manager.search_memories(
            query="Q4æˆ˜ç•¥ ç»è¥ç›®æ ‡ æ ¸å¿ƒæŒ‡æ ‡ äº§å“çº¿",
            memory_type="global",
            enabled_only=True,
            limit=5
        )

        memory_context = "\n".join([
            f"{i+1}. {m.content}\n   æ¥æº: {m.metadata.get('source', 'æœªçŸ¥')}"
            for i, m in enumerate(memories)
        ])

        # 3. æ„å»ºLLMæç¤ºè¯
        prompt = f"""
ä½ æ˜¯CEOçš„æˆ˜ç•¥åŠ©æ‰‹ï¼Œæ­£åœ¨ç”Ÿæˆæ¯æ—¥æ™¨æŠ¥çš„"ç»è¥æ‘˜è¦"éƒ¨åˆ†ã€‚

## ä¼ä¸šè®°å¿†ä¸å…±è¯†
{memory_context if memory_context else "æš‚æ— ç›¸å…³è®°å¿†"}

## ç»è¥æ•°æ®ï¼ˆè¿‘7å¤©ï¼‰
{json.dumps(metrics_data, ensure_ascii=False, indent=2)}

## ä»»åŠ¡
ç”Ÿæˆä¸€ä»½ç®€æ´çš„ç»è¥æ‘˜è¦ï¼ˆ3-5å¥è¯ï¼‰ï¼ŒåŒ…æ‹¬ï¼š
1. æ ¸å¿ƒæŒ‡æ ‡è¡¨ç°ï¼ˆè¥æ”¶ã€è½¬åŒ–ç‡ã€è·å®¢æˆæœ¬ç­‰ï¼‰
2. ä¸å…¬å¸æˆ˜ç•¥ç›®æ ‡çš„å¯¹é½æƒ…å†µï¼ˆå¦‚æœæœ‰è®°å¿†çš„è¯ï¼‰
3. éœ€è¦CEOå…³æ³¨çš„ç‚¹

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
{{
  "summary_text": "ç»è¥æ‘˜è¦æ–‡æœ¬ï¼ˆ3-5å¥è¯ï¼‰",
  "key_metrics": [
    {{"name": "æŒ‡æ ‡å", "value": "å€¼", "status": "æ­£å¸¸/å¼‚å¸¸", "change": "å˜åŒ–"}},
    ...
  ],
  "evidence_ids": ["å¼•ç”¨çš„è®°å¿†ID"]
}}
"""

        try:
            response = await self.llm_client.async_chat_completion(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5
            )

            # æ£€æŸ¥é”™è¯¯
            if "error" in response:
                print(f"    âœ— LLMè°ƒç”¨å¤±è´¥: {response['error']}")
                return {
                    "summary_text": "LLMæœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
                    "key_metrics": [],
                    "evidence_ids": []
                }

            content = response.get("content") or ""
            content = content.strip()

            if not content:
                print(f"    âœ— LLMè¿”å›ç©ºå†…å®¹")
                return {
                    "summary_text": "LLMè¿”å›ç©ºå†…å®¹",
                    "key_metrics": [],
                    "evidence_ids": []
                }

            # æå–JSONå†…å®¹
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            else:
                # å°è¯•æ‰¾åˆ°JSONå¯¹è±¡ï¼ˆä»ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª }ï¼‰
                start_idx = content.find('{')
                end_idx = content.rfind('}')
                if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                    content = content[start_idx:end_idx+1]

            # å†æ¬¡æ£€æŸ¥æ˜¯å¦ä¸ºç©º
            if not content:
                print(f"    âœ— æå–JSONåå†…å®¹ä¸ºç©º")
                return {
                    "summary_text": "JSONæå–å¤±è´¥",
                    "key_metrics": [],
                    "evidence_ids": []
                }

            result = json.loads(content)
            result["evidence_ids"] = [m.id for m in memories]
            result["data_source"] = "analytics.json"

            print(f"    âœ“ æ±‡æ€»å®Œæˆ: {len(result.get('key_metrics', []))} ä¸ªå…³é”®æŒ‡æ ‡")

            # æ¨é€èŠ‚ç‚¹å®ŒæˆçŠ¶æ€
            await self.event_bus.emit(
                event_name="node_status",
                data={
                    "node": "summary",
                    "status": "completed",
                    "message": f"æ±‡æ€»å®Œæˆï¼š{len(result.get('key_metrics', []))} ä¸ªå…³é”®æŒ‡æ ‡"
                },
                source="s8_decision_agent"
            )

            return result

        except Exception as e:
            print(f"    âœ— æ±‡æ€»å¤±è´¥: {e}")
            return {
                "summary_text": "ç»è¥æ•°æ®åŠ è½½å¤±è´¥",
                "key_metrics": [],
                "evidence_ids": []
            }

    async def _node_risk_detection(self, summary: Dict) -> Dict:
        """èŠ‚ç‚¹2: å¼‚å¸¸/é£é™©åŠ©æ‰‹"""
        print("  [èŠ‚ç‚¹2] å¼‚å¸¸/é£é™©åŠ©æ‰‹...")

        # æ¨é€èŠ‚ç‚¹å¼€å§‹çŠ¶æ€
        await self.event_bus.emit(
            event_name="node_status",
            data={
                "node": "risk",
                "status": "working",
                "message": "æ­£åœ¨è¯†åˆ«å¼‚å¸¸å’Œé£é™©..."
            },
            source="s8_decision_agent"
        )

        # å¬å›ç›¸å…³ä¼šè®®å…±è¯†
        memories = self.memory_manager.search_memories(
            query="è½¬åŒ–ç‡ è¥é”€ç­–ç•¥ æ¸ é“ é£é™©",
            memory_type="global",
            enabled_only=True,
            limit=5
        )

        memory_context = "\n".join([
            f"{i+1}. {m.content} (æ¥æº: {m.metadata.get('source', 'æœªçŸ¥')})"
            for i, m in enumerate(memories)
        ])

        prompt = f"""
ä½ æ˜¯é£é™©è¯†åˆ«ä¸“å®¶ï¼Œæ­£åœ¨ä¸ºCEOè¯†åˆ«éœ€è¦å…³æ³¨çš„å¼‚å¸¸å’Œé£é™©ã€‚

## ä¼ä¸šè®°å¿†ï¼ˆä¼šè®®å…±è¯†ï¼‰
{memory_context if memory_context else "æš‚æ— ç›¸å…³è®°å¿†"}

## å½“å‰ç»è¥æƒ…å†µ
{summary.get('summary_text', '')}

æŒ‡æ ‡è¯¦æƒ…ï¼š
{json.dumps(summary.get('key_metrics', []), ensure_ascii=False, indent=2)}

## ä»»åŠ¡
è¯†åˆ«2-3ä¸ªéœ€è¦CEOå…³æ³¨çš„å¼‚å¸¸æˆ–é£é™©ï¼Œæ¯ä¸ªåŒ…æ‹¬ï¼š
- å¼‚å¸¸æè¿°
- å¯èƒ½åŸå› ï¼ˆ**å¿…é¡»ç»“åˆ"ä¼ä¸šè®°å¿†"ä¸­çš„ä¼šè®®å…±è¯†æ¥åˆ†æ**ï¼‰
- ä¸¥é‡ç¨‹åº¦

**å…³é”®çº¦æŸ**ï¼š
1. ä½ çš„åˆ†æå¿…é¡»åŸºäºå…¬å¸å·²è¾¾æˆçš„å…±è¯†
2. å¦‚æœæŸä¸ªå¼‚å¸¸ä¸ä¼šè®®å†³è®®çš„é‡ç‚¹æ–¹å‘ç›¸å…³ï¼ŒåŠ¡å¿…æŒ‡å‡º
3. ä¸è¦æå‡ºä¸ä¼šè®®å†³è®®ç›¸æ‚–çš„è§‚ç‚¹

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
{{
  "risks": [
    {{
      "title": "å¼‚å¸¸æ ‡é¢˜",
      "description": "å¼‚å¸¸æè¿°",
      "reason": "å¯èƒ½åŸå› ï¼ˆå¿…é¡»ç»“åˆä¼ä¸šè®°å¿†åˆ†æï¼‰",
      "severity": "high/medium/low",
      "evidence_ids": ["ç›¸å…³çš„è®°å¿†IDæˆ–æ•°æ®ID"]
    }}
  ]
}}
"""

        try:
            response = await self.llm_client.async_chat_completion(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6
            )

            # æ£€æŸ¥é”™è¯¯
            if "error" in response:
                print(f"    âœ— LLMè°ƒç”¨å¤±è´¥: {response['error']}")
                return {"risks": []}

            content = response.get("content") or ""
            content = content.strip()

            if not content:
                print(f"    âœ— LLMè¿”å›ç©ºå†…å®¹")
                return {"risks": []}

            # æå–JSONå†…å®¹
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            else:
                # å°è¯•æ‰¾åˆ°JSONå¯¹è±¡ï¼ˆä»ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª }ï¼‰
                start_idx = content.find('{')
                end_idx = content.rfind('}')
                if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                    content = content[start_idx:end_idx+1]

            # å†æ¬¡æ£€æŸ¥æ˜¯å¦ä¸ºç©º
            if not content:
                print(f"    âœ— æå–JSONåå†…å®¹ä¸ºç©º")
                return {"risks": []}

            result = json.loads(content)

            # è¡¥å……evidence_ids
            for risk in result.get("risks", []):
                if not risk.get("evidence_ids"):
                    risk["evidence_ids"] = [m.id for m in memories[:2]]

            print(f"    âœ“ è¯†åˆ«åˆ° {len(result.get('risks', []))} ä¸ªé£é™©")

            # æ¨é€èŠ‚ç‚¹å®ŒæˆçŠ¶æ€
            await self.event_bus.emit(
                event_name="node_status",
                data={
                    "node": "risk",
                    "status": "completed",
                    "message": f"è¯†åˆ«åˆ° {len(result.get('risks', []))} ä¸ªé£é™©"
                },
                source="s8_decision_agent"
            )

            return result

        except Exception as e:
            print(f"    âœ— é£é™©è¯†åˆ«å¤±è´¥: {e}")
            return {"risks": []}

    async def _node_recommendations(self, summary: Dict, risks: Dict) -> Dict:
        """èŠ‚ç‚¹3: ç­–ç•¥å»ºè®®åŠ©æ‰‹ï¼ˆæ ¸å¿ƒèŠ‚ç‚¹ï¼‰"""
        print("  [èŠ‚ç‚¹3] ç­–ç•¥å»ºè®®åŠ©æ‰‹...")

        # æ¨é€èŠ‚ç‚¹å¼€å§‹çŠ¶æ€
        await self.event_bus.emit(
            event_name="node_status",
            data={
                "node": "recommendation",
                "status": "working",
                "message": "æ­£åœ¨ç”Ÿæˆç­–ç•¥å»ºè®®..."
            },
            source="s8_decision_agent"
        )

        # å¬å›ä¼šè®®å…±è¯†ï¼ˆå¿…é¡»ï¼ï¼‰
        memories = self.memory_manager.search_memories(
            query="Q4æˆ˜ç•¥ è¥é”€ç­–ç•¥ äº§å“çº¿ æ¸ é“ é¢„ç®—",
            memory_type="global",
            enabled_only=True,
            limit=5
        )

        memory_context = "\n".join([
            f"{i+1}. {m.content}\n   æ¥æº: {m.metadata.get('source', 'æœªçŸ¥')}\n   ID: {m.id}"
            for i, m in enumerate(memories)
        ])

        prompt = f"""
ä½ æ˜¯èµ„æ·±æˆ˜ç•¥é¡¾é—®ï¼Œæ­£åœ¨ä¸ºCEOå‡†å¤‡æ¯æ—¥ç®€æŠ¥çš„"ä¸‰é¡¹ä¼˜å…ˆè¡ŒåŠ¨"ã€‚

## ä¼ä¸šè®°å¿†ä¸å…±è¯†ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼ï¼‰
{memory_context if memory_context else "æš‚æ— ç›¸å…³è®°å¿†"}

## å½“å‰æƒ…å†µ
{summary.get('summary_text', '')}

## å¼‚å¸¸ä¸é£é™©
{json.dumps(risks.get('risks', []), ensure_ascii=False, indent=2)}

## ä»»åŠ¡
æ ¹æ®ä¸Šè¿°ä¿¡æ¯ï¼Œç»™å‡º**ä¸‰é¡¹ä¼˜å…ˆè¡ŒåŠ¨å»ºè®®**ï¼Œæ¯é¡¹åŒ…æ‹¬ï¼š
- è¡ŒåŠ¨æ ‡é¢˜ï¼ˆå…·ä½“ã€å¯æ‰§è¡Œï¼‰
- è¯¦ç»†æè¿°
- ä¸ºä»€ä¹ˆï¼ˆå¿…é¡»å¼•ç”¨"ä¼ä¸šè®°å¿†"æˆ–"ç»è¥æ•°æ®"ï¼‰
- é¢„æœŸæ•ˆæœï¼ˆé‡åŒ–ï¼‰
- å»ºè®®è´£ä»»äºº
- å»ºè®®æˆªæ­¢æœŸ

## å…³é”®çº¦æŸï¼ˆéå¸¸é‡è¦ï¼ï¼‰
1. æ‰€æœ‰å»ºè®®å¿…é¡»ä¸"ä¼ä¸šè®°å¿†"ä¸­çš„ä¼šè®®å…±è¯†æ–¹å‘**å®Œå…¨ä¸€è‡´**
2. ç¦æ­¢æå‡ºä¸ä¼šè®®å†³è®®ç›¸æ‚–çš„å»ºè®®
   - ä¾‹å¦‚ï¼šä¼šè®®è¯´"é‡ç‚¹å°çº¢ä¹¦"ï¼Œå°±ä¸èƒ½å»ºè®®"æ”¾å¼ƒå°çº¢ä¹¦"
3. å¦‚æœç»è¥æ•°æ®ä¸ä¼šè®®å…±è¯†å†²çªï¼Œä¼˜å…ˆæŒ‰ä¼šè®®å…±è¯†æ–¹å‘è°ƒæ•´ç­–ç•¥
4. æ¯ä¸ªå»ºè®®å¿…é¡»æ˜ç¡®å¼•ç”¨ä¾æ®ï¼ˆå“ªæ¬¡ä¼šè®®ã€å“ªæ¡æ•°æ®ï¼‰
5. å¦‚æœæ²¡æœ‰ç›¸å…³çš„ä¼ä¸šè®°å¿†ï¼Œå¯ä»¥ç»™é€šç”¨å»ºè®®ï¼Œä½†è¦è¯´æ˜"æœªæ‰¾åˆ°ç›¸å…³å…±è¯†"

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
{{
  "actions": [
    {{
      "title": "è¡ŒåŠ¨æ ‡é¢˜",
      "description": "è¯¦ç»†æè¿°ï¼ˆ2-3å¥è¯ï¼‰",
      "reason": "ä¾æ®ï¼ˆå¿…é¡»å¼•ç”¨å…·ä½“çš„è®°å¿†æˆ–æ•°æ®ï¼‰",
      "evidence_ids": ["memory_id_1", "data_id"],
      "expected_impact": "é¢„æœŸæå‡è½¬åŒ–ç‡0.5ä¸ªç™¾åˆ†ç‚¹",
      "suggested_owner": "å¸‚åœºéƒ¨æç»ç†",
      "suggested_deadline": "2025-11-05",
      "priority": 1
    }},
    ...
  ]
}}
"""

        try:
            response = await self.llm_client.async_chat_completion(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7
            )

            # æ£€æŸ¥é”™è¯¯
            if "error" in response:
                print(f"    âœ— LLMè°ƒç”¨å¤±è´¥: {response['error']}")
                return {"actions": []}

            content = response.get("content") or ""
            content = content.strip()

            if not content:
                print(f"    âœ— LLMè¿”å›ç©ºå†…å®¹")
                return {"actions": []}

            # æå–JSONå†…å®¹
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            else:
                # å°è¯•æ‰¾åˆ°JSONå¯¹è±¡ï¼ˆä»ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª }ï¼‰
                start_idx = content.find('{')
                end_idx = content.rfind('}')
                if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                    content = content[start_idx:end_idx+1]

            # å†æ¬¡æ£€æŸ¥æ˜¯å¦ä¸ºç©º
            if not content:
                print(f"    âœ— æå–JSONåå†…å®¹ä¸ºç©º")
                return {"actions": []}

            result = json.loads(content)

            # è¡¥å……evidence_ids
            for action in result.get("actions", []):
                if not action.get("evidence_ids"):
                    action["evidence_ids"] = [m.id for m in memories[:2]]

            print(f"    âœ“ ç”Ÿæˆ {len(result.get('actions', []))} é¡¹å»ºè®®")

            # æ¨é€èŠ‚ç‚¹å®ŒæˆçŠ¶æ€
            await self.event_bus.emit(
                event_name="node_status",
                data={
                    "node": "recommendation",
                    "status": "completed",
                    "message": f"ç”Ÿæˆ {len(result.get('actions', []))} é¡¹å»ºè®®"
                },
                source="s8_decision_agent"
            )

            return result

        except Exception as e:
            print(f"    âœ— å»ºè®®ç”Ÿæˆå¤±è´¥: {e}")
            return {"actions": []}

    async def confirm_actions(self, actions_with_assignment: List[Dict], sync_to_board: bool = False) -> Dict:
        """
        èŠ‚ç‚¹4: è¡ŒåŠ¨æ¸…å•/æŒ‡æ´¾åŠ©æ‰‹ï¼ˆå…³é”®èŠ‚ç‚¹ï¼‰

        Args:
            actions_with_assignment: ç¡®è®¤åçš„è¡ŒåŠ¨ï¼ˆå«è´£ä»»äººå’Œæˆªæ­¢æœŸï¼‰
            sync_to_board: æ˜¯å¦åŒæ­¥åˆ°çœ‹æ¿

        Returns:
            ä»»åŠ¡åˆ—è¡¨å’ŒåŒæ­¥æ—¥å¿—
        """
        print("  [èŠ‚ç‚¹4] è¡ŒåŠ¨æ¸…å•/æŒ‡æ´¾åŠ©æ‰‹...")

        tasks = []
        for action in actions_with_assignment:
            task_id = f"TASK_{datetime.now().strftime('%Y%m%d')}_{datetime.now().strftime('%H%M%S')}"

            task = {
                "task_id": task_id,
                "title": action["title"],
                "description": action.get("description", ""),
                "owner": action["owner"],
                "deadline": action["deadline"],
                "status": "å¾…å¼€å§‹",
                "created_at": datetime.now().isoformat(),
                "created_by": "CEO",
                "evidence_ids": action.get("evidence_ids", []),
                "expected_impact": action.get("expected_impact", "")
            }

            tasks.append(task)

        # åŒæ­¥åˆ°çœ‹æ¿ï¼ˆæ¨¡æ‹Ÿï¼‰
        sync_log = ""
        if sync_to_board:
            sync_log = f"å·²ç”Ÿæˆ {len(tasks)} ä¸ªä»»åŠ¡ï¼Œæ¨¡æ‹ŸåŒæ­¥åˆ°é£ä¹¦çœ‹æ¿"
            print(f"    âœ“ {sync_log}")
        else:
            sync_log = f"å·²ç”Ÿæˆ {len(tasks)} ä¸ªä»»åŠ¡ï¼ŒæœªåŒæ­¥åˆ°çœ‹æ¿"

        # æ›´æ–°æŠ¥å‘ŠçŠ¶æ€
        if self.current_report:
            self.current_report["status"] = "confirmed"
            self.current_report["tasks"] = tasks
            self.current_report["sync_log"] = sync_log

        # è§¦å‘äº‹ä»¶
        await self.event_bus.emit(
            event_name=EventNames.ACTION_CONFIRMED,
            data={
                "tasks": tasks,
                "sync_to_board": sync_to_board,
                "count": len(tasks)
            },
            source="s8_decision_agent"
        )

        return {
            "success": True,
            "tasks": tasks,
            "sync_log": sync_log
        }

    async def on_memory_updated(self, event_data: Dict):
        """
        ç›‘å¬è®°å¿†æ›´æ–°äº‹ä»¶ï¼Œä¸»åŠ¨ä¿®æ­£æŠ¥å‘Šï¼ˆæ–¹æ¡ˆæ ¸å¿ƒï¼ï¼‰

        Args:
            event_data: äº‹ä»¶æ•°æ®
        """
        # é˜²æŠ–ï¼šå¦‚æœæ­£åœ¨å¤„ç†ï¼Œè·³è¿‡
        if S8DecisionAgent._is_processing_update:
            print(f"â­ï¸  æ­£åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡æ­¤æ¬¡äº‹ä»¶")
            return

        S8DecisionAgent._is_processing_update = True
        try:
            print(f"ğŸ”” æ£€æµ‹åˆ°è®°å¿†æ›´æ–°äº‹ä»¶ï¼Œæ­£åœ¨åˆ†ææ˜¯å¦éœ€è¦ä¿®æ­£æŠ¥å‘Š...")

            # æ£€æŸ¥æ˜¯å¦æœ‰å½“å‰æŠ¥å‘Š
            if not self.current_report:
                print("  â†’ æš‚æ— å½“å‰æŠ¥å‘Šï¼Œè·³è¿‡")
                return

            # æ£€æŸ¥æŠ¥å‘Šæ˜¯å¦å·²ç¡®è®¤ï¼ˆå·²ç¡®è®¤çš„ä¸å†ä¿®æ­£ï¼‰
            if self.current_report.get("status") == "confirmed":
                print("  â†’ æŠ¥å‘Šå·²ç¡®è®¤ï¼Œä¸å†ä¿®æ­£")
                return

            # è·å–æ–°è®°å¿†
            new_memory_ids = event_data.get("memory_ids", [])
            if not new_memory_ids:
                return

            new_memories = []
            for mid in new_memory_ids:
                memories = self.memory_manager.get_all_memories()
                for m in memories:
                    if m.id == mid:
                        new_memories.append(m)
                        break

            if not new_memories:
                return

            print(f"  â†’ æ£€æµ‹åˆ° {len(new_memories)} æ¡æ–°è®°å¿†")

            # åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®æ­£
            should_update = await self._should_update_report(new_memories)

            if should_update["should_update"]:
                print(f"  â†’ éœ€è¦ä¿®æ­£æŠ¥å‘Š: {should_update['reason']}")

                # ç”Ÿæˆä¿®æ­£ç‰ˆæœ¬
                self.report_version = "v2.0"
                new_report = await self.generate_report()

                # ç”Ÿæˆå¯¹æ¯”
                comparison = await self._generate_comparison(
                    old_report=self.current_report,
                    new_report=new_report,
                    trigger_memories=new_memories
                )

                # è§¦å‘æŠ¥å‘Šæ›´æ–°äº‹ä»¶
                await self.event_bus.emit(
                    event_name=EventNames.REPORT_UPDATED,
                    data={
                        "old_version": "v1.0",
                        "new_version": "v2.0",
                        "comparison": comparison,
                        "trigger_source": "memory_updated",
                        "new_memories": [m.to_dict() for m in new_memories]
                    },
                    source="s8_decision_agent"
                )

                print("  âœ“ æŠ¥å‘Šå·²æ›´æ–°å¹¶æ¨é€é€šçŸ¥")
            else:
                print(f"  â†’ æ— éœ€ä¿®æ­£: {should_update.get('reason', 'ä¸å½±å“å½“å‰å»ºè®®')}")

        finally:
            # é‡ç½®å¤„ç†æ ‡å¿—
            S8DecisionAgent._is_processing_update = False

    async def _should_update_report(self, new_memories: List) -> Dict:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®æ­£æŠ¥å‘Š"""
        current_recommendations = self.current_report.get("recommendations", {}).get("actions", [])

        memory_contents = "\n".join([f"- {m.content}" for m in new_memories])
        current_actions = "\n".join([f"- {a['title']}" for a in current_recommendations])

        prompt = f"""
ä½ æ˜¯æˆ˜ç•¥åˆ†æä¸“å®¶ã€‚åˆ¤æ–­æ–°å½•å…¥çš„ä¼šè®®è®°å½•æ˜¯å¦éœ€è¦ä¿®æ­£å½“å‰çš„CEOæ™¨æŠ¥å»ºè®®ã€‚

## å½“å‰å»ºè®®ï¼ˆv1.0ï¼‰
{current_actions}

## åˆšåˆšå½•å…¥çš„ä¼šè®®è®°å½•
{memory_contents}

## ä»»åŠ¡
åˆ¤æ–­ï¼šæ–°ä¼šè®®å†…å®¹æ˜¯å¦ä¸å½“å‰å»ºè®®å­˜åœ¨**å†²çª**æˆ–**é‡è¦è¡¥å……**ï¼Ÿ

éœ€è¦ä¿®æ­£çš„æƒ…å†µï¼š
1. æ–°ä¼šè®®æ˜ç¡®äº†æˆ˜ç•¥æ–¹å‘ï¼Œä¸å½“å‰å»ºè®®ä¸ä¸€è‡´
2. æ–°ä¼šè®®æŠ«éœ²äº†å…³é”®æ•°æ®ï¼Œæ”¹å˜äº†ä¼˜å…ˆçº§
3. æ–°ä¼šè®®å·²æœ‰æ˜ç¡®å†³è®®ï¼Œå½“å‰å»ºè®®æœªä½“ç°

è¾“å‡ºJSONï¼š
{{
  "should_update": true/false,
  "reason": "åŸå› è¯´æ˜"
}}
"""

        try:
            response = await self.llm_client.async_chat_completion(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )

            content = response.get("content", "")
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()

            return json.loads(content)

        except Exception as e:
            print(f"    âœ— åˆ¤æ–­å¤±è´¥: {e}")
            return {"should_update": False, "reason": "åˆ¤æ–­å¤±è´¥"}

    async def _generate_comparison(self, old_report: Dict, new_report: Dict, trigger_memories: List) -> Dict:
        """ç”ŸæˆæŠ¥å‘Šå¯¹æ¯”"""
        old_actions = old_report.get("recommendations", {}).get("actions", [])
        new_actions = new_report.get("recommendations", {}).get("actions", [])

        # ä½¿ç”¨LLMç”Ÿæˆä¿®æ­£è¯´æ˜
        prompt = f"""
ä½ æ˜¯CEOå†³ç­–åŠ©æ‰‹ã€‚åˆšåˆšå…¬å¸å½•å…¥äº†æ–°çš„ä¼šè®®è®°å½•ï¼Œä½ é‡æ–°åˆ†æåä¿®æ­£äº†å»ºè®®ã€‚ç°åœ¨éœ€è¦å‘CEOè§£é‡Šä¿®æ­£åŸå› ã€‚

## æ—§å»ºè®®ï¼ˆv1.0ï¼‰
{json.dumps([{"title": a["title"], "reason": a["reason"]} for a in old_actions], ensure_ascii=False, indent=2)}

## æ–°å»ºè®®ï¼ˆv2.0ï¼‰
{json.dumps([{"title": a["title"], "reason": a["reason"]} for a in new_actions], ensure_ascii=False, indent=2)}

## è§¦å‘ä¿®æ­£çš„ä¼šè®®è®°å½•
{chr(10).join([f"- {m.content}" for m in trigger_memories])}

## ä»»åŠ¡
ç”Ÿæˆä¿®æ­£è¯´æ˜ï¼Œå‘CEOè§£é‡Šï¼š
1. ä¸ºä»€ä¹ˆä¿®æ”¹äº†æ¯æ¡å»ºè®®ï¼Ÿ
2. æ–°ä¼šè®®è®°å½•ä¸­çš„å“ªäº›ä¿¡æ¯å½±å“äº†å†³ç­–ï¼Ÿ

è¾“å‡ºJSONï¼š
{{
  "revision_summary": "æ€»ä½“ä¿®æ­£åŸå› ï¼ˆ2-3å¥è¯ï¼‰",
  "revision_reasons": [
    {{
      "action_index": 0,
      "old_title": "æ—§å»ºè®®æ ‡é¢˜",
      "new_title": "æ–°å»ºè®®æ ‡é¢˜",
      "why_changed": "ä¿®æ­£åŸå› ï¼ˆ1-2å¥è¯ï¼‰"
    }},
    ...
  ]
}}
"""

        try:
            response = await self.llm_client.async_chat_completion(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6
            )

            content = response.get("content", "")
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()

            comparison = json.loads(content)
            comparison["old_version"] = "v1.0"
            comparison["new_version"] = "v2.0"
            comparison["trigger_source"] = [m.metadata.get("source", "æœªçŸ¥") for m in trigger_memories]

            return comparison

        except Exception as e:
            print(f"    âœ— å¯¹æ¯”ç”Ÿæˆå¤±è´¥: {e}")
            return {
                "revision_summary": "åŸºäºæ–°çš„ä¼šè®®è®°å½•ï¼Œå·²æ›´æ–°å»ºè®®",
                "revision_reasons": []
            }
